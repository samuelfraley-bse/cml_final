{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c785ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Constants that almost never change ----\n",
    "\n",
    "# Targets\n",
    "TARGET_COL_CLASS = \"HOSPITAL_EXPIRE_FLAG\"\n",
    "TARGET_COL_REG   = \"LOS\"\n",
    "\n",
    "# ID columns (adjust to match your file)\n",
    "ID_COLS = [\n",
    "    \"ICUSTAY_ID\",\n",
    "    \"SUBJECT_ID\",\n",
    "    \"HADM_ID\",\n",
    "]\n",
    "\n",
    "def get_paths():\n",
    "    \"\"\"\n",
    "    Return BASE_DIR, TRAIN_PATH, TEST_PATH based on the current notebook location.\n",
    "\n",
    "    Assumes this notebook lives in:\n",
    "        cml_final/notebooks/HEF/hef_prep.ipynb\n",
    "    and data lives in:\n",
    "        cml_final/data/raw/MIMIC III dataset HEF/\n",
    "    \"\"\"\n",
    "    base_dir = Path.cwd().parents[1]  # .../cml_final\n",
    "    raw_dir = base_dir / \"data\" / \"raw\" / \"MIMIC III dataset HEF\"\n",
    "\n",
    "    train_path = raw_dir / \"mimic_train_HEF.csv\"\n",
    "    test_path  = raw_dir / \"mimic_test_HEF.csv\"\n",
    "\n",
    "    return base_dir, train_path, test_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ecb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data():\n",
    "    \"\"\"\n",
    "    Load raw train and test CSVs and return them as dataframes.\n",
    "    \"\"\"\n",
    "    base_dir, train_path, test_path = get_paths()\n",
    "    print(\"Base dir:\", base_dir)\n",
    "    print(\"Train path:\", train_path)\n",
    "    print(\"Test path:\", test_path)\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df  = pd.read_csv(test_path)\n",
    "\n",
    "    print(\"Train shape:\", train_df.shape)\n",
    "    print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0e0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_target(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    task: str = \"class\",\n",
    "    leak_cols: list | None = None,\n",
    "    id_cols: list | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    From raw train/test:\n",
    "    - Pick target column based on task (\"class\" or \"reg\")\n",
    "    - Drop ID, leakage, and both target columns from X.\n",
    "    - Return X_train_raw, y_train, X_test_raw\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task : {\"class\", \"reg\"}\n",
    "        \"class\" -> y = HOSPITAL_EXPIRE_FLAG\n",
    "        \"reg\"   -> y = LOS\n",
    "    leak_cols : list or None\n",
    "        Extra columns to drop because they leak the target.\n",
    "        If None, no leak columns are dropped here (you can pass them from a notebook).\n",
    "    id_cols : list or None\n",
    "        ID columns to drop. If None, uses the global ID_COLS.\n",
    "    \"\"\"\n",
    "    if id_cols is None:\n",
    "        id_cols = ID_COLS\n",
    "\n",
    "    if leak_cols is None:\n",
    "        leak_cols = []\n",
    "\n",
    "    if task == \"class\":\n",
    "        target_col = TARGET_COL_CLASS\n",
    "    elif task == \"reg\":\n",
    "        target_col = TARGET_COL_REG\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown task '{task}'. Use 'class' or 'reg'.\")\n",
    "\n",
    "    # drop both targets from X to be safe\n",
    "    drop_cols_train = id_cols + leak_cols + [TARGET_COL_CLASS, TARGET_COL_REG]\n",
    "    drop_cols_test  = id_cols + leak_cols\n",
    "\n",
    "    y_train = train_df[target_col].copy()\n",
    "\n",
    "    X_train_raw = train_df.drop(columns=[c for c in drop_cols_train if c in train_df.columns])\n",
    "    X_test_raw  = test_df.drop(columns=[c for c in drop_cols_test  if c in test_df.columns])\n",
    "\n",
    "    print(f\"Task: {task} (target = {target_col})\")\n",
    "    print(\"X_train_raw shape:\", X_train_raw.shape)\n",
    "    print(\"X_test_raw shape:\", X_test_raw.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "    if task == \"class\":\n",
    "        print(\"Positive rate (death):\", y_train.mean().round(3))\n",
    "\n",
    "    return X_train_raw, y_train, X_test_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93ecaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "BP_MIN_LOWER_BOUNDS = {\n",
    "    \"SysBP_Min\":  40.0,\n",
    "    \"DiasBP_Min\": 10.0,\n",
    "    \"MeanBP_Min\": 30.0,\n",
    "}\n",
    "\n",
    "def clean_min_bp_outliers(df: pd.DataFrame,\n",
    "                          lower_bounds: dict = BP_MIN_LOWER_BOUNDS) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col, low in lower_bounds.items():\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        s = df[col]\n",
    "        mask_valid = s.notna()\n",
    "        n_valid = mask_valid.sum()\n",
    "        if n_valid == 0:\n",
    "            continue\n",
    "        below_mask = (s < low) & mask_valid\n",
    "        n_below = below_mask.sum()\n",
    "        if n_below > 0:\n",
    "            pct_valid = n_below / n_valid * 100.0\n",
    "            print(\n",
    "                f\"[clean_min_bp_outliers] {col}: \"\n",
    "                f\"setting {n_below} values ({pct_valid:.3f}% of valid) \"\n",
    "                f\"below {low} mmHg to NaN\"\n",
    "            )\n",
    "            df.loc[below_mask, col] = np.nan\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf23072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    task: str = \"class\",\n",
    "    leak_cols: list | None = None,\n",
    "    apply_fe: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Full data prep pipeline (configurable):\n",
    "\n",
    "    - Load raw train & test\n",
    "    - Split features/target based on task (\"class\" or \"reg\")\n",
    "    - Clean implausible min BPs\n",
    "    - Optionally add engineered features\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task : {\"class\", \"reg\"}\n",
    "        Which target to use (classification vs regression).\n",
    "    leak_cols : list or None\n",
    "        List of leakage column names to drop from X.\n",
    "        e.g. [\"leak1\", \"leak2\", \"leak3\"]\n",
    "    apply_fe : bool\n",
    "        If True, applies add_engineered_features().\n",
    "        If False, returns cleaned raw features only.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train, y_train, X_test\n",
    "    \"\"\"\n",
    "    train_df, test_df = load_raw_data()\n",
    "    X_train_raw, y_train, X_test_raw = split_features_target(\n",
    "        train_df=train_df,\n",
    "        test_df=test_df,\n",
    "        task=task,\n",
    "        leak_cols=leak_cols,\n",
    "    )\n",
    "\n",
    "    X_train_clean = clean_min_bp_outliers(X_train_raw)\n",
    "    X_test_clean  = clean_min_bp_outliers(X_test_raw)\n",
    "\n",
    "    if apply_fe:\n",
    "        X_train_final = add_engineered_features(X_train_clean)\n",
    "        X_test_final  = add_engineered_features(X_test_clean)\n",
    "    else:\n",
    "        X_train_final = X_train_clean\n",
    "        X_test_final  = X_test_clean\n",
    "\n",
    "    print(\"Final X_train shape:\", X_train_final.shape)\n",
    "    print(\"Final X_test shape:\", X_test_final.shape)\n",
    "\n",
    "    return X_train_final, y_train, X_test_final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
